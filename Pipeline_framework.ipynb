{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Pipeline Framework \n",
    "先拉一个大致的框架，用notebook方便叙述逻辑以及调试，等确定最终框架后我再把框架写成class，方便调用。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f3f6f72c386d1239"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import stanza\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "加载一个stanza的英文模型作为全局变量，用来分句，以及后续的处理。这个加载过程回头我写到class里面，这里为了避免重复加载先这样写。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "774419141c587d3e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nlp = stanza.Pipeline(lang='en')   "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "619c6425d0258220"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. 将文本分句\n",
    "将文本拆分成句子，方便后续以句子为单位进行事实核查。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "12099d842d305882"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def split_text(text:str)->list:\n",
    "    \"\"\"\n",
    "    Split text into sentences\n",
    "    Args:\n",
    "        text: the text to be split\n",
    "\n",
    "    Returns:\n",
    "        a list of sentences\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    return [sentence.text for sentence in doc.sentences]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c7ef9a37d15a703"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. 将句子转化成embedding\n",
    "获得每个句子的embedding，用于后续使用 cosine similarity 筛选相关句子\n",
    "\n",
    "@ CC&Lauren"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "975e184d6fe7ed7e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def sentence2embedding(sentences:list[str])->list[list[float]]:\n",
    "    \"\"\"\n",
    "    Convert sentences to embeddings\n",
    "    Args:\n",
    "        sentences: a list of sentences\n",
    "\n",
    "    Returns:\n",
    "        a list of embeddings\n",
    "    \"\"\"\n",
    "    embeddings = ____ # to be completed\n",
    "    return embeddings"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d0c16bad9c304d7a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "不确定直接获得的embeddings是不是一个矩阵，很可能是列表，这里需要一个函数将列表转化成矩阵，方便后续计算。\n",
    "\n",
    "如果后续发现矩阵规模比较大的话可以考虑使用pytorch配合GPU进行计算，这里先用numpy写一个简单的版本。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a8479e3224cb982"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def embeddinesmatric(embeddings:list[list[float]])->np.ndarray:\n",
    "    \"\"\"\n",
    "    Convert a list of embeddings to a matrix\n",
    "    Args:\n",
    "        embeddings: \n",
    "\n",
    "    Returns:\n",
    "        a matrix of embeddings, each row is an embedding\n",
    "    \"\"\"\n",
    "    \n",
    "    return ____ # to be completed"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e5ee32a8909f414"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. 筛选相关句子\n",
    "计算summary中的句子与text中的句子的cosine similarity，用于后续对每个summary中的句子，筛选原文句子中最相关的那几个。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8aaaeb9894375270"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def cosine_similarity(embed_text:np.ndarray, embed_summary: np.ndarray)->np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate the cosine similarities between sentences of summary and sentences of text\n",
    "    Args:\n",
    "        embed_text: embedding matrix of text sentences\n",
    "                    each row is an embedding\n",
    "        embed_summary: embedding matrix of summary sentences\n",
    "                    each row is an embedding\n",
    "\n",
    "    Returns:\n",
    "        a matrix of cosine similarities\n",
    "    \"\"\"\n",
    "    \n",
    "    dot_prod = embed_summary @ embed_text.T # [i,j] is the dot product of summary sentence i and text sentence j\n",
    "    norm = np.linalg.norm(embed_summary, axis=1) @ np.linalg.norm(embed_text, axis=1).T # [i,j] is the norm of summary sentence i and text sentence j\n",
    "    return dot_prod / norm"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a0e16c7add78146"
  },
  {
   "cell_type": "markdown",
   "source": [
    "找到每个summary中的句子在text中最相关的k个句子，用于后续事实核查。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4150dfa4365de0da"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def topk_related(sim_matrix:np.ndarray, k:int)->np.ndarray:\n",
    "    \"\"\"\n",
    "    Find the indices of top k related sentences in text for each sentence in summary\n",
    "    Args:\n",
    "        sim_matrix: cosine similarity matrix\n",
    "        k: number of sentences to be selected\n",
    "\n",
    "    Returns:\n",
    "        a matrix of indices\n",
    "    \"\"\"\n",
    "    return sim_matrix.argsort(axis=1)[:, -k:]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d8b0483a981dfd9e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. 事实核查\n",
    "对于每个summary中的句子，检查是否可以从text中的最相关的几个句子中推知\n",
    "1. 如果可以，返回True\n",
    "2. 否则返回False。\n",
    "\n",
    "同时返回一个概率，表示summary中的句子可以从text中的句子中获得的概率。\n",
    "\n",
    "这里先用一个简单的方法，后续可以加入根据 dependency arc 或 name entity 来判断的方法。\n",
    "\n",
    "@ hyc\n",
    "\n",
    "**PS：这部分需要使用LLM，guidance**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d2c7e34f086508c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def checker(sens_text:list[str], sen_summary:str)->(bool, float):\n",
    "    \"\"\"\n",
    "    Check if the sentence from the summary con be obtained from the sentence from the text.\n",
    "    Args:\n",
    "        sens_text: list of sentences from the text\n",
    "        sen_summary: the sentence from the summary\n",
    "\n",
    "    Returns:\n",
    "        a tuple of (bool, float)\n",
    "        bool: True if the sentence from the summary can be obtained from the sentence from the text\n",
    "        float: the probability that the sentence from the summary can be obtained from the sentence from the text\n",
    "            True: >0.5\n",
    "            False: <0.5\n",
    "    \"\"\"\n",
    "    \n",
    "    # to be completed\n",
    "    \n",
    "    \n",
    "    \n",
    "    res = ____\n",
    "    prob = ____\n",
    "    \n",
    "    return (res, prob)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9bd2cba2beadd85"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. 评估\n",
    "将上述步骤组合起来，对summary进行评估，返回一个0到1之间的分数，分数越高表示summary越好。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f46f93591cc12a7e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluate(text:str, summary:str, k:int)->float:\n",
    "    \"\"\"\n",
    "    evaluate the quality of the summary according to the given text\n",
    "    Args:\n",
    "        text: original text\n",
    "        summary: summary to be evaluated\n",
    "        k: number of sentences to be selected from the text\n",
    "\n",
    "    Returns:\n",
    "        a float number between 0 and 1, the higher the better\n",
    "    \"\"\"\n",
    "    \n",
    "    # split the text into sentences\n",
    "    sens_text = split_text(text)\n",
    "    # split the summary into sentences\n",
    "    sens_summary = split_text(summary)\n",
    "    \n",
    "    # convert sentences to embeddings\n",
    "    embed_text = sentence2embedding(sens_text)\n",
    "    embed_summary = sentence2embedding(sens_summary)\n",
    "    \n",
    "    # convert embeddings to matrix\n",
    "    embed_text_mat = embeddinesmatric(embed_text)\n",
    "    embed_summary_mat = embeddinesmatric(embed_summary)\n",
    "    \n",
    "    # calculate cosine similarity\n",
    "    sim_matrix = cosine_similarity(embed_text_mat, embed_summary_mat)\n",
    "    \n",
    "    # find top k related sentences\n",
    "    topk = topk_related(sim_matrix, k)\n",
    "    \n",
    "    # check if the sentence from the summary can be obtained from the sentence from the text\n",
    "    denominator = 0\n",
    "    numerator = 0\n",
    "    for idx, sen in enumerate(sens_summary):\n",
    "        sens_text_selected = [sens_text[i] for i in topk[idx]]\n",
    "        res, _ = checker(sens_text_selected, sen)\n",
    "        if res:\n",
    "            numerator += 1\n",
    "        denominator += 1\n",
    "    return numerator / denominator"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c33101f07b1a506d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
