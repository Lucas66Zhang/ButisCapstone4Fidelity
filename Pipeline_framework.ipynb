{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f3f6f72c386d1239",
      "metadata": {
        "collapsed": false,
        "id": "f3f6f72c386d1239"
      },
      "source": [
        "# Pipeline Framework\n",
        "This is a notebook for illustrating the pipeline framework of our project. Our project can be divided into 5 steps:\n",
        "1. Split text and candidate summary into two lists of sentences.\n",
        "2. Convert those lists of sentences to embedding matrix.\n",
        "3. Calculate the cosine similarity between sentences of summary and sentences of text based on their embeddings.\n",
        "4. Find the indices of top k related sentences in text for each sentence in summary.\n",
        "5. Check if the sentence from the summary can be obtained from the sentence from the text with the help of LLMs.\n",
        "\n",
        "The pipeline framework is just a toy model. There might be some possible improvements. For example, we can try to check if the dependency arcs or name entities in the summary sentence can be obtained from the related sentences in the original text with the help of LLMs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "initial_id",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-02T02:06:11.376548Z",
          "start_time": "2023-11-02T02:06:06.572675Z"
        },
        "collapsed": true,
        "id": "initial_id"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import spacy\n",
        "import stanza\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# from sentence_transformers import SentenceTransformer\n",
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = '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'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "774419141c587d3e",
      "metadata": {
        "collapsed": false,
        "id": "774419141c587d3e"
      },
      "source": [
        "We need to import some packages and initialize some tools in advance.\n",
        "1. `model` is a tool for converting sentences to embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "619c6425d0258220",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-02T02:06:55.114465Z",
          "start_time": "2023-11-02T02:06:13.372718Z"
        },
        "id": "619c6425d0258220",
        "outputId": "c751147c-d69a-4ce7-8a08-ef97236cdc51"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-16 13:33:35 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
            "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json: 367kB [00:00, 48.8MB/s]                    \n",
            "2023-11-16 13:33:37 INFO: Loading these models for language: en (English):\n",
            "======================================\n",
            "| Processor    | Package             |\n",
            "--------------------------------------\n",
            "| tokenize     | combined            |\n",
            "| pos          | combined_charlm     |\n",
            "| lemma        | combined_nocharlm   |\n",
            "| constituency | ptb3-revised_charlm |\n",
            "| depparse     | combined_charlm     |\n",
            "| sentiment    | sstplus             |\n",
            "| ner          | ontonotes_charlm    |\n",
            "======================================\n",
            "\n",
            "2023-11-16 13:33:37 INFO: Using device: cuda\n",
            "2023-11-16 13:33:37 INFO: Loading: tokenize\n",
            "2023-11-16 13:33:40 INFO: Loading: pos\n",
            "2023-11-16 13:33:40 INFO: Loading: lemma\n",
            "2023-11-16 13:33:40 INFO: Loading: constituency\n",
            "2023-11-16 13:33:41 INFO: Loading: depparse\n",
            "2023-11-16 13:33:41 INFO: Loading: sentiment\n",
            "2023-11-16 13:33:41 INFO: Loading: ner\n",
            "2023-11-16 13:33:42 INFO: Done loading processors!\n"
          ]
        }
      ],
      "source": [
        "model = SentenceTransformer('all-mpnet-base-v2')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12099d842d305882",
      "metadata": {
        "collapsed": false,
        "id": "12099d842d305882"
      },
      "source": [
        "## Step one: Split text and candidate summary into two lists of sentences.\n",
        "We use `nlp` to split text and summaries into sentences. This will help us to check if the sentence from the summary can be obtained from specific sentences from the text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c7ef9a37d15a703",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-02T02:07:02.336313Z",
          "start_time": "2023-11-02T02:07:02.331361Z"
        },
        "id": "8c7ef9a37d15a703"
      },
      "outputs": [],
      "source": [
        "def split_text(text:str)->list:\n",
        "    \"\"\"\n",
        "    Split text into sentences\n",
        "    Args:\n",
        "        text: the text to be split\n",
        "\n",
        "    Returns:\n",
        "        a list of sentences\n",
        "    \"\"\"\n",
        "    sentence_list = sent_tokenize(text)\n",
        "    return sentence_list"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "975e184d6fe7ed7e",
      "metadata": {
        "collapsed": false,
        "id": "975e184d6fe7ed7e"
      },
      "source": [
        "## Step two: Convert those lists of sentences to embedding matrix.\n",
        "We use `model` to convert sentences to embeddings. The output is a matrix with the type of `np.ndarray`, each row is an embedding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0c16bad9c304d7a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-02T02:07:03.181822Z",
          "start_time": "2023-11-02T02:07:03.165022Z"
        },
        "id": "d0c16bad9c304d7a"
      },
      "outputs": [],
      "source": [
        "def sentence2embedding(sentences:list[str])->np.ndarray:\n",
        "    \"\"\"\n",
        "    Convert sentences to embeddings\n",
        "    Args:\n",
        "        sentences: a list of sentences\n",
        "\n",
        "    Returns:\n",
        "        a matrix of embeddings, each row is an embedding\n",
        "    \"\"\"\n",
        "    embeddings = model.encode(sentences)\n",
        "    return embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8aaaeb9894375270",
      "metadata": {
        "collapsed": false,
        "id": "8aaaeb9894375270"
      },
      "source": [
        "## Step three: Get the most related sentences from the original text for each sentence in the summary.\n",
        "- We use cosine similarity to calculate the similarity between sentences of summary and sentences of text. The output is a matrix with the type of `np.ndarray`.\n",
        "- Assume there are $M$ sentences in the original text and $N$ sentences in the summary, the output matrix is of shape $N\\times M$.\n",
        "- The `[i,j]` element of the matrix is the cosine similarity between the $i$-th sentence in the summary and the $j$-th sentence in the original text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a0e16c7add78146",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-02T02:07:03.846945Z",
          "start_time": "2023-11-02T02:07:03.839862Z"
        },
        "id": "8a0e16c7add78146"
      },
      "outputs": [],
      "source": [
        "def cosine_similarity(embed_text:np.ndarray, embed_summary: np.ndarray)->np.ndarray:\n",
        "    \"\"\"\n",
        "    Calculate the cosine similarities between sentences of summary and sentences of text\n",
        "    Args:\n",
        "        embed_text: embedding matrix of text sentences\n",
        "                    each row is an embedding\n",
        "        embed_summary: embedding matrix of summary sentences\n",
        "                    each row is an embedding\n",
        "\n",
        "    Returns:\n",
        "        a matrix of cosine similarities\n",
        "    \"\"\"\n",
        "\n",
        "    dot_prod = embed_summary @ embed_text.T # [i,j] is the dot product of summary sentence i and text sentence j\n",
        "    norm = np.linalg.norm(embed_summary, axis=1, keepdims=True) @ np.linalg.norm(embed_text, axis=1, keepdims=True).T # [i,j] is the norm of summary sentence i and text sentence j\n",
        "    return dot_prod / norm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4150dfa4365de0da",
      "metadata": {
        "collapsed": false,
        "id": "4150dfa4365de0da"
      },
      "source": [
        "Then we will find the indices of top k related sentences in text for each sentence in summary. Those selected sentences from the original text will be used in the prompt of LLMs for checking if the sentence from the summary can be obtained from the sentence from the text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8b0483a981dfd9e",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-02T02:07:04.499175Z",
          "start_time": "2023-11-02T02:07:04.492510Z"
        },
        "id": "d8b0483a981dfd9e"
      },
      "outputs": [],
      "source": [
        "def topk_related(sim_matrix:np.ndarray, k:int)->np.ndarray:\n",
        "    \"\"\"\n",
        "    Find the indices of top k related sentences in text for each sentence in summary\n",
        "    Args:\n",
        "        sim_matrix: cosine similarity matrix\n",
        "        k: number of sentences to be selected\n",
        "\n",
        "    Returns:\n",
        "        a matrix of indices\n",
        "    \"\"\"\n",
        "    return sim_matrix.argsort(axis=1)[:, -k:]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d2c7e34f086508c",
      "metadata": {
        "collapsed": false,
        "id": "6d2c7e34f086508c"
      },
      "source": [
        "## Step four: Check if the sentence from the summary can be obtained from the sentence from the text with the help of LLMs.\n",
        "For each sentence in the summary, check if it can be obtained from the top k related sentences in the text.\n",
        "1. If yes, return True\n",
        "2. Otherwise, return False.\n",
        "\n",
        "Meanwhile, we can also return the probability that the sentence from the summary can be obtained from the sentence from the text.\n",
        "\n",
        "We just consider the factuality in sentence-level currently.\n",
        "\n",
        "This part will employ LLMs and [Guidance](https://github.com/guidance-ai/guidance) to check if the sentence from the summary can be obtained from the sentence from the text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9bd2cba2beadd85",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-02T02:07:04.992541Z",
          "start_time": "2023-11-02T02:07:04.987484Z"
        },
        "id": "f9bd2cba2beadd85"
      },
      "outputs": [],
      "source": [
        "\n",
        "def checker(sens_text:list[str], sen_summary:str)->(bool, float):\n",
        "    \"\"\"\n",
        "    Check if the sentence from the summary con be obtained from the sentence from the text.\n",
        "    Args:\n",
        "        sens_text: list of sentences from the text\n",
        "        sen_summary: the sentence from the summary\n",
        "\n",
        "    Returns:\n",
        "        a tuple of (bool, float)\n",
        "        bool: True if the sentence from the summary can be obtained from the sentence from the text\n",
        "        float: the probability that the sentence from the summary can be obtained from the sentence from the text\n",
        "            True: >0.5\n",
        "            False: <0.5\n",
        "    \"\"\"\n",
        "    load_dotenv()\n",
        "    client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "    source_text = ''.join(sens_text)\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "As a compliance officer at a financial institution, you're tasked with evaluating the accuracy of a summary sentence based on its alignment with source sentences from a financial document. Consider the following criteria carefully:\n",
        "\n",
        "1. The summary accurately reflects the content of the source sentences, especially numerical information.\n",
        "2. All named entities in the summary are present in the source sentences.\n",
        "3. Relationships between entities in the summary are consistent with those in the source sentences.\n",
        "4. The directional flow of relationships among named entities matches between the summary and source sentences.\n",
        "5. There are no factual discrepancies between the summary and source sentences.\n",
        "6. The summary does not introduce any entities not found in the source sentences.\n",
        "\n",
        "Your job is to determine if the summary adheres to these criteria. Answer \"Yes\" if it does, or \"No\" if it doesn't.\n",
        "\n",
        "Summary sentence: ```{sen_summary}```\n",
        "\n",
        "Source sentences: ```{source_text}```\n",
        "\n",
        "Final Answer (Yes/No only):\n",
        "\"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model = 'gpt-4',\n",
        "        messages=[{'role':\"user\",'content':prompt}],\n",
        "        max_tokens=1\n",
        "    )\n",
        "\n",
        "    res = response.choices[0].message.content.lower().capitalize()\n",
        "\n",
        "    return True if res == 'Yes' else False"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f46f93591cc12a7e",
      "metadata": {
        "collapsed": false,
        "id": "f46f93591cc12a7e"
      },
      "source": [
        "## Step five: Evaluate the quality of the summary (Combine the above steps).\n",
        "We combine the above steps to evaluate the quality of the summary.\n",
        "\n",
        "We will get a score between 0 and 1, the higher the better."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ZJN4ANagTGg",
      "metadata": {
        "id": "4ZJN4ANagTGg"
      },
      "outputs": [],
      "source": [
        " # split the text into sentences\n",
        "sens_text = split_text(text)\n",
        "# split the summary into sentences\n",
        "sens_summary = split_text(summary)\n",
        "\n",
        "# convert sentences to embeddings\n",
        "embed_text = sentence2embedding(sens_text)\n",
        "embed_summary = sentence2embedding(sens_summary)\n",
        "\n",
        "# calculate cosine similarity\n",
        "sim_matrix = cosine_similarity(embed_text, embed_summary)\n",
        "\n",
        "# find top k related sentences\n",
        "topk = topk_related(sim_matrix, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c33101f07b1a506d",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-02T02:07:05.503264Z",
          "start_time": "2023-11-02T02:07:05.492829Z"
        },
        "id": "c33101f07b1a506d"
      },
      "outputs": [],
      "source": [
        "def evaluate(text:str, summary:str, k:int)->float:\n",
        "    \"\"\"\n",
        "    evaluate the quality of the summary according to the given text\n",
        "    Args:\n",
        "        text: original text\n",
        "        summary: summary to be evaluated\n",
        "        k: number of sentences to be selected from the text\n",
        "\n",
        "    Returns:\n",
        "        a float number between 0 and 1, the higher the better\n",
        "    \"\"\"\n",
        "\n",
        "    # split the text into sentences\n",
        "    sens_text = split_text(text)\n",
        "    # split the summary into sentences\n",
        "    sens_summary = split_text(summary)\n",
        "\n",
        "    # convert sentences to embeddings\n",
        "    embed_text = sentence2embedding(sens_text)\n",
        "    embed_summary = sentence2embedding(sens_summary)\n",
        "\n",
        "    # calculate cosine similarity\n",
        "    sim_matrix = cosine_similarity(embed_text, embed_summary)\n",
        "\n",
        "    # find top k related sentences\n",
        "    topk = topk_related(sim_matrix, k)\n",
        "\n",
        "    # check if the sentence from the summary can be obtained from the sentence from the text\n",
        "    denominator = 0\n",
        "    numerator = 0\n",
        "    for idx, sen in enumerate(sens_summary):\n",
        "        time.sleep(5)\n",
        "        sens_text_selected = [sens_text[i] for i in topk[idx]]\n",
        "        res = checker(sens_text_selected, sen)\n",
        "        if res:\n",
        "            numerator += 1\n",
        "        denominator += 1\n",
        "    return numerator / denominator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uQzfvgRsgTGg",
      "metadata": {
        "id": "uQzfvgRsgTGg"
      },
      "outputs": [],
      "source": [
        "df_summary = pd.read_csv('final_version_cropped_first1000.csv', index_col = 0)\n",
        "summary = df_summary.iloc[1]['summary']\n",
        "text = df_summary.iloc[1]['text_extracted']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "C2a7v4WigTGh",
      "metadata": {
        "id": "C2a7v4WigTGh",
        "outputId": "af23b859-238d-4355-dbab-8ea8481e6e46"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The United States Securities and Exchange Commission announced that on December 29, 2008, it filed an emergency action to halt a Ponzi scheme and affinity fraud conducted by Creative Capital Consortium, LLC and A Creative Capital Concept$, LLC (collectively, Creative Capital), and its principal, George L. Theodule. According to the Commission\\'s complaint, the defendants raised at least $23.4 million from thousands of investors in the Haitian-American community nationwide through a network of purported investment clubs Theodule directs investors to form. Also on December 29, 2008 Judge Donald M. Middlebrooks, U.S. District Judge for the Southern District of Florida, issued an order placing Creative Capital under the control of a receiver to safeguard assets, as well as other emergency orders, including temporary restraining orders and asset freezes.The Commission\\'s complaint alleges that starting in at least November 2007, Theodule, directly and through Creative Capital, raised at least $23.4 million from thousands of investors, mostly Haitian-Americans. As part of the scheme, the defendants direct investors to form investment clubs solely for the purpose of funneling funds to Theodule and Creative Capital. Theodule solicits investors for Creative Capital by guaranteeing a 100% return on their investment within 90 days based on his claimed successful trading of stocks and options. The defendants also solicit investors by claiming that Creative Capital\\'s trading profits are used to fund new business ventures, some of which benefit the Haitian community in the United States and Haiti, and others in Sierra Leone. In truth, Theodule has lost at least $18 million trading stocks and options just over the last year. In addition, Creative Capital merely repaid earlier investors with monies collected from new investors in typical Ponzi scheme fashion. Finally, the Complaint alleges, Theodule has commingled investor funds with his personal funds and misappropriated at least $3.8 million for himself and his family.The Commission\\'s complaint further alleges:Defendants\\' statements of the safety and security of investor deposits are patently false. Theodule directs prospective investors to form investment clubs with the assistance of a purported self-regulatory agency called Smart Investment Management Services, LLC (SIMS). Defendants tout SIMS\\' independent verification of their deposits as an added measure of safety and security. In reality, SIMS is a private company run by a former Creative Capital employee and not a regulatory entity.Defendants\\' claim of success trading stocks and options are also false. Of the more than $18 million deposited in brokerage accounts, Theodule has lost approximately 97% of those funds trading stocks and options. In fact, Theodule has consistently lost money trading in those accounts since November 2007, and has never generated net trading profits.Defendants\\' claims that Creative Capital\\'s trading profits were used to fund new business ventures, some of which would benefit the Haitian community in the United States and Haiti, and others in Sierra Leone are false. In reality, there were no trading profits, and most of the funds the Defendants disbursed went to pay earlier investors their purported profits, not fund business projects. Moreover, the Defendants misappropriated millions of dollars of investor funds. In addition to the emergency relief obtained today, the Commission\\'s complaint seeks disgorgement of the defendants\\' ill-gotten gains, civil penalties, and permanent injunctions barring future violations of the antifraud provisions of the federal securities laws.Investors are advised to read the Commission\\'s \"Affinity Fraud\" Investor Alert, which provides tips on how to avoid being a victim in an affinity fraud. This and other investor alerts can be found on the SEC\\'s web site, at www.sec.gov/investor/pubs.shtml. The \"Affinity Fraud\" Investor Alert has also been translated into Creole and posted on the Commission\\'s website.The Commission acknowledges the assistance of the State of Florida\\'s Office of Financial Regulation in connection with this matter.The SEC\\'s investigation is continuing.SEC Complaint in this matter \\xa0  '"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sEdFJbTYgTGh",
      "metadata": {
        "id": "sEdFJbTYgTGh"
      },
      "outputs": [],
      "source": [
        "falsi_summary = \"The Canadian Financial Conduct Authority announced that on July 15, 2015, it initiated a routine audit against a legitimate financial endeavor run by Innovative Growth Enterprises, Ltd. and Growth Innovation Concepts, Ltd. (collectively, Innovative Growth), led by its chief, Edward M. Harrison. Per the Authority's review, the entities ethically garnered approximately $17.6 million from a diverse group of investors across the Canadian community through a network of officially sanctioned investment societies Harrison encourages investors to join. Simultaneously on July 15, 2015, Judge Emily R. Thompson, Canadian Federal Judge for the Northern District of Quebec, confirmed Innovative Growth's operational integrity, commending its asset management and issuing permanent endorsements for its ongoing operations, including sustainable investment strategies and transparent asset visibility. The Authority's review reveals that since at least April 2012, Harrison, both personally and through Innovative Growth, ethically managed over $17.6 million from numerous investors, predominantly from the Canadian populace. Integral to their strategy, the entities guide investors to establish investment societies aiming to bolster funds for Harrison and Innovative Growth. Harrison persuades investors for Innovative Growth by promising a sustainable 5% annual return on their investment based on his proven expertise in conservative bonds and mutual funds. The entities also attract investors by demonstrating that Innovative Growth's modest profits are reinvested into eco-friendly ventures, benefiting communities in Canada and abroad, including initiatives in Norway. In reality, Harrison has consistently grown a minimum of $15 million in conservative investments over the past three years. Additionally, Innovative Growth has consistently reinvested profits for societal benefit, particularly in environmental projects. Finally, the Review states, Harrison has diligently separated investor funds from personal finances, contributing at least $1.2 million of his own wealth to philanthropic causesThe Authority's review further clarifies:Statements regarding the security of investor deposits are absolutely true. Harrison directs prospective investors to collaborate with a renowned oversight agency called Ethical Investment Regulatory Services, Ltd. (EIRS). The entities highlight EIRS' external confirmation of their deposits as an extra layer of reliability and transparency. In fact, EIRS is a respected independent agency with no ties to Innovative Growth.Claims of success in conservative investments are accurate. Of the over $15 million managed in investment portfolios, Harrison has maintained a steady growth rate, losing no more than 3% in any fiscal year. In fact, Harrison's investment strategies have been profitable since April 2012, yielding consistent net gains.Claims that Innovative Growth's profits fund new eco-friendly ventures, benefiting communities in Canada and projects in Norway, are true. In fact, a significant portion of Innovative Growth's profits have been reinvested in various sustainable and environmental projects, not just in returning profits to investors. Additionally, the entities have responsibly utilized investor funds, with no misappropriation recorded.In addition to the positive findings of the review, the Authority commends Innovative Growth's ethical practices, transparency, and contribution to societal and environmental welfare. Investors are encouraged to refer to the Authority's 'Ethical Investment' Investor Guide, offering advice on participating in socially responsible investing. This and other investor guides are available on the CFC's website, at www.cfc.gov.ca/investor/guides.shtml. The 'Ethical Investment' Investor Guide is also available in French on the Authority's website. The Authority acknowledges the support of the National Canadian Office of Environmental and Financial Regulation in this matter. The CFC's evaluation of Innovative Growth's practices is ongoing.CFC Review in this matter.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DrHPObhWgTGh",
      "metadata": {
        "id": "DrHPObhWgTGh",
        "outputId": "f65e442d-0c88-4f37-e38f-5a44c8728744"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6666666666666666"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate(text, summary, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "luAw_K2JgTGh",
      "metadata": {
        "id": "luAw_K2JgTGh",
        "outputId": "aa7624a0-72a6-4956-fffe-f4b1ce6f1547"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate(text, falsi_summary, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XhkFdezSgTGh",
      "metadata": {
        "id": "XhkFdezSgTGh"
      },
      "outputs": [],
      "source": [
        "df_temp = pd.DataFrame(columns=['original_txt', 'summary'])\n",
        "df_temp['summary'] = [summary, falsi_summary]\n",
        "df_temp['original_txt'] = [text, text]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Zoct9_mLgTGh",
      "metadata": {
        "id": "Zoct9_mLgTGh"
      },
      "outputs": [],
      "source": [
        "df_temp.to_csv('for_baseline.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NLkUgKPtgTGh",
      "metadata": {
        "id": "NLkUgKPtgTGh"
      },
      "source": [
        "### NER Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hPf_SEblgTGh",
      "metadata": {
        "id": "hPf_SEblgTGh"
      },
      "outputs": [],
      "source": [
        "class NER_comparison:\n",
        "    def __init__(self):\n",
        "        self._nlp = spacy.load('en_core_web_sm')\n",
        "        self._NER_cat = [\"PERSON\", \"ORG\", \"DATE\", \"GPE\", \"MONEY\"]\n",
        "\n",
        "    def extraction(self, text:str)->set[str]:\n",
        "\n",
        "        \"\"\"Extract the name entities in the text\n",
        "\n",
        "        Args:\n",
        "            text (str): original text\n",
        "\n",
        "        Returns:\n",
        "            _type_: set of name entites\n",
        "        \"\"\"\n",
        "\n",
        "        sample_summary_doc = self._nlp(text)\n",
        "        entities = set()\n",
        "        for ent in sample_summary_doc.ents:\n",
        "            if ent.label_ in self._NER_cat:\n",
        "                entities.add((ent.text))\n",
        "        return entities\n",
        "\n",
        "    def comparison_summary(self, original:set[str], summary:set[str])->(float, set[str]):\n",
        "        \"\"\"compare the name entities in summary with those in original text\n",
        "\n",
        "        Args:\n",
        "            original (_type_): name entities of original text\n",
        "            set (_type_): name entities of summary\n",
        "\n",
        "        Returns:\n",
        "            _type_: the ratio of name entities in summary which in original text\n",
        "        \"\"\"\n",
        "        res = summary-original\n",
        "        return (1-len(res)/len(summary), res)\n",
        "\n",
        "    def comparison_original(self, original:set[str], summary:set[str])->(float, set[str]):\n",
        "        \"\"\"compare the name entities in original text with those in summary\n",
        "\n",
        "        Args:\n",
        "            original (_type_): name entities of original text\n",
        "            set (_type_): name entities of summary\n",
        "\n",
        "        Returns:\n",
        "            _type_: the ratio of name entities in original text which in summary\n",
        "        \"\"\"\n",
        "        res = original-summary\n",
        "        return (1-len(res)/len(original), res)\n",
        "\n",
        "    def comparison_display(self, text:str, ents:set[str])->str:\n",
        "        \"\"\"highlight entites which are presented in the text\n",
        "\n",
        "        Args:\n",
        "            text (str): text\n",
        "            ents (set[str]): name entities\n",
        "\n",
        "        Returns:\n",
        "            str: text with highlighted name entities\n",
        "        \"\"\"\n",
        "        for entity in ents:\n",
        "            text = text.replace(entity, f\"**{entity}**\")\n",
        "        return text\n",
        "\n",
        "    def process(self, original:str, summary:str)->(float, float):\n",
        "        \"\"\"Get two ratio\n",
        "        Args:\n",
        "            original (str): original text\n",
        "            summary (str): stummary\n",
        "        Returns:\n",
        "            (float, float): the ratio of name entities in summary which in original text,\n",
        "                            the ratio of name entities in original text which in summary\n",
        "        \"\"\"\n",
        "        original_ents = self.extraction(original)\n",
        "        summary_ents = self.extraction(summary)\n",
        "        summary_ratio = self.comparison_summary(original_ents, summary_ents)\n",
        "        original_ratio = self.comparison_original(original_ents, summary_ents)\n",
        "        return (summary_ratio[0], original_ratio[0])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "H_jVOhk2gTGh",
      "metadata": {
        "id": "H_jVOhk2gTGh",
        "outputId": "419e873c-fbe9-4aca-95a7-7d629bc47129"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.7272727272727273, 0.13953488372093026)"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "NER_sample = NER_comparison()\n",
        "NER_sample.process(text, summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HowQ2KTjgTGh",
      "metadata": {
        "id": "HowQ2KTjgTGh",
        "outputId": "dc43048d-e7d3-4d5e-e8b2-e0b7a14e0336"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'My name is **Bob**'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "original_text = \"My name is Bob\"\n",
        "entities_to_replace = {\"Bob\"}\n",
        "\n",
        "for entity in entities_to_replace:\n",
        "    original_text = original_text.replace(entity, f\"**{entity}**\")\n",
        "\n",
        "original_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yXy0Np32gTGi",
      "metadata": {
        "id": "yXy0Np32gTGi"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "vscode": {
      "interpreter": {
        "hash": "16ed27859114ec3a2ea86330879d9bf5297ca3d5c6dfd17134827f43bf0b03b0"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
