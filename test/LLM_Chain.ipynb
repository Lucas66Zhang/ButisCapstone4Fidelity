{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "from  langchain import LLMChain, HuggingFacePipeline, PromptTemplate\n",
    "import pandas as pd\n",
    "import guidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>summary</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The United States Securities and Exchange Comm...</td>\n",
       "      <td>NOTICE: Attorneys MUST Indicate All Re-filed C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>According to the Commission's complaint, the d...</td>\n",
       "      <td>The Defendants have engaged in a fraudulent Po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Also on December 29, 2008 Judge Donald M. Midd...</td>\n",
       "      <td>NATURE OF SUIT (Place an “x” in One Box Ont 4 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The Commission's complaint alleges that starti...</td>\n",
       "      <td>21. The investment clubs pool investor funds a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>As part of the scheme, the defendants direct i...</td>\n",
       "      <td>NOTICE: Attorneys MUST Indicate All Re-filed C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            summary  \\\n",
       "0           0  The United States Securities and Exchange Comm...   \n",
       "1           1  According to the Commission's complaint, the d...   \n",
       "2           2  Also on December 29, 2008 Judge Donald M. Midd...   \n",
       "3           3  The Commission's complaint alleges that starti...   \n",
       "4           4  As part of the scheme, the defendants direct i...   \n",
       "\n",
       "                                                text  \n",
       "0  NOTICE: Attorneys MUST Indicate All Re-filed C...  \n",
       "1  The Defendants have engaged in a fraudulent Po...  \n",
       "2  NATURE OF SUIT (Place an “x” in One Box Ont 4 ...  \n",
       "3  21. The investment clubs pool investor funds a...  \n",
       "4  NOTICE: Attorneys MUST Indicate All Re-filed C...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('../data/sample_input_for_checker1.csv')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('NOTICE: Attorneys MUST Indicate All Re-filed Cases Below. \\r\\n'\n",
      " 'I. (a) PLAINTIFFS DEFENDANTS SECURITIES AND EXCHANGE COMMISSION CREATIVE '\n",
      " 'CAPITAL CONSORTIUM, LLC, A CREATIVE CAPITAL CONCEPTS, LLC, and GEORGE L. '\n",
      " 'THEODULE (b) County of Residence of First Listed Plaintiff County of '\n",
      " 'Residence of First Listed Degh Palm Beach \\r\\n'\n",
      " '(EXCEPT IN U.S. PLAINTIFF CA: UN U.S. PL, CARES ONLY) \\r\\n'\n",
      " '(c) Attomcy’s (Firm Name.RELIEF REQUESTED \\r\\n'\n",
      " 'WHEREFORE, the Commission respectfully requests the Court: \\r\\n'\n",
      " '| Declaratory Relief \\r\\n'\n",
      " 'Declare, determine and find that the Defendants have committed the '\n",
      " 'violations of the \\r\\n'\n",
      " 'federal securities laws alleged herein.Penalties Issue an Order directing '\n",
      " 'the Defendants to pay civil money penalties pursuant to Section \\r\\n'\n",
      " '21(d) of the Exchange Act [15 U.S.C. § 78u(d)]. \\r\\n'\n",
      " '8 of 10 \\r\\n'\n",
      " 'Case 9:08-cv-81565-DTKH34. | Thus, Theodule misrepresented the safety and '\n",
      " 'security of the Creative Capital investments when he led investors to '\n",
      " 'believe: they could withdraw their funds any time after the initial 90-day '\n",
      " 'investment period; there was no risk; and SIMS verified the security of '\n",
      " 'their funds.CLAIM FOR RELIEF Fraud in Violation of Section 10(b) of the '\n",
      " 'Exchange Act and Rule 10b-5 Thereunder \\r\\n'\n",
      " '35.29. | However, Creative Capital hid those losses from current and '\n",
      " 'prospective investors, paying principal and purported profits to existing '\n",
      " 'investment clubs and individual \\r\\n'\n",
      " 'investors of approximately $15.2 million from new investor funds.NATURE OF '\n",
      " 'SUIT (Place an “x” in One Box Ont 4 ONTRA po rorts TO TPORFEITURE/PENALTY | '\n",
      " 'BANKRUPTCY | COTHER STATUTES | \\r\\n'\n",
      " '3 110 Insurance PERSONAL INJURY PERSONAL INJURY |3 610 Agriculure 3 422 '\n",
      " 'Appeal 2% USC 15K 400 State Reapportionment 3120 Manne J 310 Airplane 3362 '\n",
      " 'Personal Injury - 620 Other Food & Drug 3 423 Withdrawal 3 410 Antitrust 3 '\n",
      " '130 Miller Act 3.315 Airplane Product Med. Malpractice 625 Drug Related '\n",
      " 'Seizure 2K USC 157 J 430 Banks and Banking 3 140 Negotiable Instrument '\n",
      " 'Liability 365 Personal Injury - of Property 21 USC &RI J 450 Commerce J 150 '\n",
      " 'Recovery of Overpaymem | I 320 Assault, Libel & Product Liability 630 Liquor '\n",
      " 'Laws J 460 Deportation & Enforcement of Judgment Slander J 36% Asbestos '\n",
      " 'Personal 640 R.R. & Truck J X20 Copyrights D470 Racketeer InQuenced and J '\n",
      " '1St Medicare Ait 3 330 Federal Employers’ 650 Airline Regs. D X30 Patent '\n",
      " 'Corrupt Organientions 7-152 Recovery of Defauited Liability ii 660 '\n",
      " 'Occupational 3 840 Trademark D480 Consumer Credit Student Loans 3 340 Marine '\n",
      " 'Safety/Health 3 490 Cable-Sat TV (Excl. Veterans) 3345 Marine Product 370 '\n",
      " 'Other Fraud 690 Other 3 10 Selective Service 183 Recovery of Overpayment '\n",
      " \"Liability 371 Truth in Lending X50 Securities Commodities of Veteran's \"\n",
      " 'Benetits 3350 Motor Vehicle 380 Other Personal 710 Pair Labor Standards J '\n",
      " 'X61 HIA (1395 Exchange J 160 Stockholders’ Suits 3-455 Motor Vehicle '\n",
      " 'Property Damage Act 3 X62 Black Lung (923) J X75 Customer Challenge 190 '\n",
      " 'Other Contract Product Liability 38S Property Damage 720 Labor/Mymt, '\n",
      " 'Relations | 863 OIWC/DIWW (405(2) 12USC 3410 3-195 Conteact Product '\n",
      " 'Liability [J 360 Other Personal Product Liability 730 Labus/MgmtReporing | J '\n",
      " 'X64 SSID Title XVI D x90 Other Statutory Actions 2196 Franchise Injury & '\n",
      " 'Disclosure Act 3_ 865 RSI (405(g)) D XYL Agricultural Acts \\r\\n'\n",
      " '3 740 Ruilway Labor Act 3 ¥92 Economic Stabilization Act 270 Land '\n",
      " 'Condemnation D 44} Voring J $10 Motions w Vacate | 790 Other Labor '\n",
      " 'Litigation [X70 Tuxes (U.S. PlaintitT 893 Environmental Matters 220 '\n",
      " 'Foreclosure J 442 Employment Sentence 3 79t Empl. Ret. Inc, Securit ur '\n",
      " 'Defendant) R94 Energy Allocation Act \\r\\n'\n",
      " '230 Rent Lease & Ejectment | 3 443 Housing!Asset Freeze and Sworn '\n",
      " 'Accountings \\r\\n'\n",
      " 'Issue an Order freezing the assets of all Defendants until further Order of '\n",
      " 'the Court and \\r\\n'\n",
      " '7 of 10 \\r\\n'\n",
      " 'Case 9:08-cv-81565-DTKH36. Starting no later than November 2007, the '\n",
      " 'Defendants, directly and indirectly, by use of the means and instrumentality '\n",
      " 'of interstate commerce, and of the mails in connection with \\r\\n'\n",
      " 'the purchase or sale of securities, have been knowingly, willfully or '\n",
      " 'recklessly: (a) employing \\r\\n'\n",
      " '6 of 10 \\r\\n'\n",
      " 'Case 9:08-cv-81565-DTKHi \\r\\n'\n",
      " 'COMPLAINT FOR INJUNCTIVE AND OTHER RELIEF \\r\\n'\n",
      " 'Plaintiff Securities and Exchange Commission alleges: \\r\\n'\n",
      " 'INTRODUCTION \\r\\n'\n",
      " 'L. The Commission brings this action to enjoin Creative Capital Consortium, '\n",
      " 'LLC (“Consortium”), A Creative Capital Concept$, LLC (“Concept$”) '\n",
      " '(collectively “Creative Capital” or “the Companies”), and George L. Theodule '\n",
      " 'from continuing to defraud investors through their violations of the '\n",
      " 'antifraud provisions of the federal securities laws.')\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(df1.iloc[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The United States Securities and Exchange Commission announced that on '\n",
      " 'December 29, 2008, it filed an emergency action to halt a Ponzi scheme and '\n",
      " 'affinity fraud conducted by Creative Capital Consortium, LLC and A Creative '\n",
      " 'Capital Concept$, LLC (collectively, Creative Capital), and its principal, '\n",
      " 'George L. Theodule.')\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(df1.iloc[0]['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a10a3ee722814817be3f1f640bdadb31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    top_p=0.95,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    device_map=0,\n",
    "    temperature=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFacePipeline(pipeline = pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "falsify_template1 = \"\"\"\n",
    "\n",
    "Given the input text, manipulate its content to produce a totally falsified version. \n",
    "Ensure that the falsified text is coherent, grammatically correct, and appears plausible. \n",
    "Use dependency-based manipulations such as changing subjects, objects, or inverting relationships to craft the new falsified text.\n",
    "Answer the falsified text only, explaination is not required.\n",
    "\n",
    "Input text: ```{reference_summary}```\n",
    "Falsified text (No explanation required):\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "falsify_template2 = \"\"\"\n",
    "\n",
    "Given the input text, manipulate the content and falsify the all facts to produce a totally falsified version. \n",
    "Ensure that the falsified text is coherent, grammatically correct, and appears plausible. \n",
    "Answer the falsified text only, explaination is not required.\n",
    "\n",
    "Input text: ```{reference_summary}```\n",
    "Falsified text (No explanation required):\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "falsify_template3 = \"\"\"\n",
    "\n",
    "Generate a completely falsified version of the input text by altering the facts presented. The result should be coherent and grammatically correct, while also maintaining a semblance of plausibility. It should not be an outright absurd or impossible scenario but should represent a believable, though untrue, alternative to the actual facts.\n",
    "Answer the falsified text only, explaination is not required.\n",
    "\n",
    "Input text: ```{reference_summary}```\n",
    "\n",
    "Falsified text (No explanation required):\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_summary = df1.iloc[0]['summary']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('```Creative Capital Consortium, LLC and A Creative Capital Concept$, LLC '\n",
      " '(collectively, Creative Capital) announced that on December 29, 2008, it '\n",
      " 'filed an emergency action to halt a legitimate business operation and '\n",
      " 'charitable donation conducted by The United States Securities and Exchange '\n",
      " 'Commission, and its principal, George L. Theodule.```')\n"
     ]
    }
   ],
   "source": [
    "falsify_prompt = PromptTemplate(template=falsify_template1, input_variables=[\"reference_summary\"])\n",
    "llm_chain = LLMChain(llm=llm, prompt=falsify_prompt)\n",
    "output1 = llm_chain.run(reference_summary)\n",
    "pprint.pprint(output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('```The United States Securities and Exchange Commission revealed that on '\n",
      " 'December 29, 2008, it launched an urgent initiative to support a legitimate '\n",
      " 'business model and combat fraudulent activities conducted by a consortium of '\n",
      " 'reputable financial institutions, led by Goldman Sachs Group, Inc. and '\n",
      " 'JPMorgan Chase & Co. (collectively, the Consortium), and its CEOs, John F. '\n",
      " 'Kennedy and Jamie Dimon.```\\n'\n",
      " '\\n'\n",
      " 'Would you like me to generate another falsified text?')\n"
     ]
    }
   ],
   "source": [
    "falsify_prompt = PromptTemplate(template=falsify_template2, input_variables=[\"reference_summary\"])\n",
    "llm_chain = LLMChain(llm=llm, prompt=falsify_prompt)\n",
    "output2 = llm_chain.run(reference_summary)\n",
    "pprint.pprint(output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('```The United States Securities and Exchange Commission revealed that on '\n",
      " 'December 29, 2008, it brought an emergency case to stop a legitimate '\n",
      " 'business operation conducted by Creative Capital Consortium, LLC and A '\n",
      " 'Creative Capital Concept$, LLC (together, Creative Capital), and its '\n",
      " 'founder, Rachel J. Smith. The fraud involved a novel investment strategy '\n",
      " 'that had been extensively tested and proven to yield consistent returns.```')\n"
     ]
    }
   ],
   "source": [
    "falsify_prompt = PromptTemplate(template=falsify_template3, input_variables=[\"reference_summary\"])\n",
    "llm_chain = LLMChain(llm=llm, prompt=falsify_prompt)\n",
    "output3 = llm_chain.run(reference_summary)\n",
    "pprint.pprint(output3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The United States Securities and Exchange Commission announced that on '\n",
      " 'December 29, 2008, it filed an emergency action to halt a Ponzi scheme and '\n",
      " 'affinity fraud conducted by Creative Capital Consortium, LLC and A Creative '\n",
      " 'Capital Concept$, LLC (collectively, Creative Capital), and its principal, '\n",
      " 'George L. Theodule.')\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(df1.iloc[0]['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "template1 = \"\"\"\n",
    "\n",
    "You are a compliance officer who works at a financial institution. You will be provided with a summary sentence and a set of source sentences. \n",
    "Check if the summary sentence is a good summary of the source sentences from Named Entity and Named Entity Relationship perspectives.\n",
    "Please answer either \"True\" or \"False\" only, explaination is not needed.\n",
    "\n",
    "Source sentences: ```{source}```\n",
    "Summary sentence: ```{summary}```\n",
    "\n",
    "Final Answer (True/False only): \n",
    "           \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = df1.iloc[0]['text']\n",
    "true_summary = df1.iloc[0]['summary']\n",
    "false_summary1 = output1\n",
    "false_summary2 = output2\n",
    "false_summary3 = output3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(template=template1, input_variables=[\"source\", \"summary\"])\n",
    "llm_chain = LLMChain(prompt=prompt, \n",
    "                     llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "' True'\n"
     ]
    }
   ],
   "source": [
    "result1 = llm_chain.run(source=source, summary=true_summary)\n",
    "pprint.pprint(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "' True'\n"
     ]
    }
   ],
   "source": [
    "result1 = llm_chain.run(source=source, summary=false_summary1)\n",
    "pprint.pprint(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "' True'\n"
     ]
    }
   ],
   "source": [
    "result1 = llm_chain.run(source=source, summary=false_summary2)\n",
    "pprint.pprint(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "' False'\n"
     ]
    }
   ],
   "source": [
    "result1 = llm_chain.run(source=source, summary=false_summary3)\n",
    "pprint.pprint(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "template2 = \"\"\"\n",
    "\n",
    "You are a compliance officer who works at a financial institution. You will be provided with a suspicious summary sentence and a set of broken source sentences from a financial document. \n",
    "Clean up the source sentences first and check if the summary sentence follow every standards:\n",
    "1. The summary sentence can be summarized from source sentences with no factual error especially on numbers.\n",
    "2. All Name Entities in summary sentence is also in source sentences.\n",
    "3. All relationships between each entity in summary sentence should exist in source sentences.\n",
    "4. The directions of all relationships between each name entites in summary sentence should matched up the relationships in source sentences.\n",
    "5. The summary sentence should not have any factual error compare with source sentences.\n",
    "6. There should not be any made-up entities in summary sentence.\n",
    "\n",
    "Answer false if any of the above standards is violated, otherwise answer true.\n",
    "Please answer either \"True\" or \"False\" only, explaination is not needed.\n",
    "\n",
    "Summary sentence: ```{summary}```\n",
    "\n",
    "Source sentences: ```{source}```\n",
    "\n",
    "Final Answer (True/False only): \n",
    "           \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "' True'\n",
      "' True'\n",
      "' True'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yiche\\.conda\\envs\\Butis\\lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "' True'\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate(template=template2, input_variables=[\"source\", \"summary\"])\n",
    "llm_chain = LLMChain(prompt=prompt, \n",
    "                     llm=llm)\n",
    "result1 = llm_chain.run(source=source, summary=true_summary)\n",
    "pprint.pprint(result1)\n",
    "result1 = llm_chain.run(source=source, summary=false_summary1)\n",
    "pprint.pprint(result1)\n",
    "result1 = llm_chain.run(source=source, summary=false_summary2)\n",
    "pprint.pprint(result1)\n",
    "result1 = llm_chain.run(source=source, summary=false_summary3)\n",
    "pprint.pprint(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "template3 = \"\"\"\n",
    "\n",
    "You are a compliance officer at a financial institution evaluating a summary sentence against source sentences from a financial document. Ensure the summary adheres to these criteria:\n",
    "\n",
    "1. It accurately represents the source, especially numerical data.\n",
    "2. It contains only named entities present in the source.\n",
    "3. It reflects existing relationships between entities as in the source.\n",
    "4. It preserves the direction of these relationships accurately.\n",
    "5. It is free of factual errors in comparison with the source.\n",
    "6. It introduces no fictitious entities.\n",
    "Your task is to determine if the summary meets all the above standards based solely on the given sentences.\n",
    "\n",
    "Answer false if any of the above standards is violated, otherwise answer true.\n",
    "Please answer either \"True\" or \"False\" only, explaination is not needed.\n",
    "\n",
    "Source sentences: {source}\n",
    "\n",
    "Summary sentence: {summary}\n",
    "\n",
    "Final Answer (True/False only): \n",
    "           \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "' True'\n",
      "' True'\n",
      "' True'\n",
      "(' False\\n'\n",
      " '\\n'\n",
      " 'Please clarify whether the provided summary sentence accurately reflects the '\n",
      " 'source sentences and whether it complies with the given criteria.')\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate(template=template3, input_variables=[\"source\", \"summary\"])\n",
    "llm_chain = LLMChain(prompt=prompt, \n",
    "                     llm=llm)\n",
    "result1 = llm_chain.run(source=source, summary=true_summary)\n",
    "pprint.pprint(result1)\n",
    "result1 = llm_chain.run(source=source, summary=false_summary1)\n",
    "pprint.pprint(result1)\n",
    "result1 = llm_chain.run(source=source, summary=false_summary2)\n",
    "pprint.pprint(result1)\n",
    "result1 = llm_chain.run(source=source, summary=false_summary3)\n",
    "pprint.pprint(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "template4 = \"\"\"\n",
    "\n",
    "Evaluate the compliance of a summary sentence derived from a set of sentences in a financial document. Adhere to the following verification standards:\n",
    "1. Entity consistency: Check that all named entities in the summary are extracted from the source.\n",
    "2. Relationship verification: Confirm that relationships between entities in the summary are present and correctly depicted in the source.\n",
    "3. Directionality check: Ensure that the direction of relationships between entities in the summary matches those in the source.\n",
    "4. Factual integrity: Ascertain that the summary is free from factual errors when compared to the source.\n",
    "5. Entity authenticity: Confirm that the summary does not create non-existent entities.\n",
    "\n",
    "Based on these criteria, determine if the summary sentence is a faithful representation of the source sentences. Respond with \"True\" if the summary complies with all standards, or \"False\" if it does not.\n",
    "Please answer either \"True\" or \"False\" only, explaination is not needed.\n",
    "\n",
    "Source Sentences: {source}\n",
    "\n",
    "Summary Sentence: {summary}\n",
    "\n",
    "Final Compliance Verification (True/False only): \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Does the summary sentence include all named entities mentioned in the source '\n",
      " 'sentences? (Yes/No) \\n'\n",
      " '\\n'\n",
      " 'Entity consistency: \\n'\n",
      " 'All named entities in the summary are extracted from the source. '\n",
      " '(True/False)\\n'\n",
      " '\\n'\n",
      " 'Relationship verification: \\n'\n",
      " 'Relationships between entities in the summary are present and correctly '\n",
      " 'depicted in the source. (True/False)\\n'\n",
      " '\\n'\n",
      " 'Directionality check: \\n'\n",
      " 'The direction of relationships between entities in the summary matches those '\n",
      " 'in the source. (True/False)\\n'\n",
      " '\\n'\n",
      " 'Factual integrity: \\n'\n",
      " 'The summary is free from factual errors when compared to the source. '\n",
      " '(True/False)\\n'\n",
      " '\\n'\n",
      " 'Entity authenticity: \\n'\n",
      " 'The summary does not create non-existent entities. (True/False)')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\GitHub\\ButisCapstone4Fidelity\\test\\LLM_Chain.ipynb Cell 33\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/GitHub/ButisCapstone4Fidelity/test/LLM_Chain.ipynb#X44sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m result1 \u001b[39m=\u001b[39m llm_chain\u001b[39m.\u001b[39mrun(source\u001b[39m=\u001b[39msource, summary\u001b[39m=\u001b[39mtrue_summary)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/GitHub/ButisCapstone4Fidelity/test/LLM_Chain.ipynb#X44sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m pprint\u001b[39m.\u001b[39mpprint(result1)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/GitHub/ButisCapstone4Fidelity/test/LLM_Chain.ipynb#X44sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m result1 \u001b[39m=\u001b[39m llm_chain\u001b[39m.\u001b[39;49mrun(source\u001b[39m=\u001b[39;49msource, summary\u001b[39m=\u001b[39;49mfalse_summary1)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/GitHub/ButisCapstone4Fidelity/test/LLM_Chain.ipynb#X44sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m pprint\u001b[39m.\u001b[39mpprint(result1)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/GitHub/ButisCapstone4Fidelity/test/LLM_Chain.ipynb#X44sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m result1 \u001b[39m=\u001b[39m llm_chain\u001b[39m.\u001b[39mrun(source\u001b[39m=\u001b[39msource, summary\u001b[39m=\u001b[39mfalse_summary2)\n",
      "File \u001b[1;32mc:\\Users\\Yiche\\.conda\\envs\\Butis\\lib\\site-packages\\langchain\\chains\\base.py:506\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[0;32m    501\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(args[\u001b[39m0\u001b[39m], callbacks\u001b[39m=\u001b[39mcallbacks, tags\u001b[39m=\u001b[39mtags, metadata\u001b[39m=\u001b[39mmetadata)[\n\u001b[0;32m    502\u001b[0m         _output_key\n\u001b[0;32m    503\u001b[0m     ]\n\u001b[0;32m    505\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m--> 506\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(kwargs, callbacks\u001b[39m=\u001b[39;49mcallbacks, tags\u001b[39m=\u001b[39;49mtags, metadata\u001b[39m=\u001b[39;49mmetadata)[\n\u001b[0;32m    507\u001b[0m         _output_key\n\u001b[0;32m    508\u001b[0m     ]\n\u001b[0;32m    510\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[0;32m    511\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    512\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`run` supported with either positional arguments or keyword arguments,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    513\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m but none were provided.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    514\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Yiche\\.conda\\envs\\Butis\\lib\\site-packages\\langchain\\chains\\base.py:306\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    305\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 306\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    307\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    308\u001b[0m final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[0;32m    309\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[0;32m    310\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Yiche\\.conda\\envs\\Butis\\lib\\site-packages\\langchain\\chains\\base.py:300\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    293\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[0;32m    294\u001b[0m     dumpd(\u001b[39mself\u001b[39m),\n\u001b[0;32m    295\u001b[0m     inputs,\n\u001b[0;32m    296\u001b[0m     name\u001b[39m=\u001b[39mrun_name,\n\u001b[0;32m    297\u001b[0m )\n\u001b[0;32m    298\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    299\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 300\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[0;32m    301\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    302\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[0;32m    303\u001b[0m     )\n\u001b[0;32m    304\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    305\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mc:\\Users\\Yiche\\.conda\\envs\\Butis\\lib\\site-packages\\langchain\\chains\\llm.py:93\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\n\u001b[0;32m     89\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m     90\u001b[0m     inputs: Dict[\u001b[39mstr\u001b[39m, Any],\n\u001b[0;32m     91\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     92\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m---> 93\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate([inputs], run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[0;32m     94\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_outputs(response)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Yiche\\.conda\\envs\\Butis\\lib\\site-packages\\langchain\\chains\\llm.py:103\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[1;34m(self, input_list, run_manager)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Generate LLM result from inputs.\"\"\"\u001b[39;00m\n\u001b[0;32m    102\u001b[0m prompts, stop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_prompts(input_list, run_manager\u001b[39m=\u001b[39mrun_manager)\n\u001b[1;32m--> 103\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm\u001b[39m.\u001b[39;49mgenerate_prompt(\n\u001b[0;32m    104\u001b[0m     prompts,\n\u001b[0;32m    105\u001b[0m     stop,\n\u001b[0;32m    106\u001b[0m     callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child() \u001b[39mif\u001b[39;49;00m run_manager \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    107\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm_kwargs,\n\u001b[0;32m    108\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Yiche\\.conda\\envs\\Butis\\lib\\site-packages\\langchain\\llms\\base.py:498\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_prompt\u001b[39m(\n\u001b[0;32m    491\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    492\u001b[0m     prompts: List[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    495\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[0;32m    496\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[0;32m    497\u001b[0m     prompt_strings \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mto_string() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m prompts]\n\u001b[1;32m--> 498\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(prompt_strings, stop\u001b[39m=\u001b[39;49mstop, callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Yiche\\.conda\\envs\\Butis\\lib\\site-packages\\langchain\\llms\\base.py:647\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[1;34m(self, prompts, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    633\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    634\u001b[0m         )\n\u001b[0;32m    635\u001b[0m     run_managers \u001b[39m=\u001b[39m [\n\u001b[0;32m    636\u001b[0m         callback_manager\u001b[39m.\u001b[39mon_llm_start(\n\u001b[0;32m    637\u001b[0m             dumpd(\u001b[39mself\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    645\u001b[0m         )\n\u001b[0;32m    646\u001b[0m     ]\n\u001b[1;32m--> 647\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate_helper(\n\u001b[0;32m    648\u001b[0m         prompts, stop, run_managers, \u001b[39mbool\u001b[39;49m(new_arg_supported), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[0;32m    649\u001b[0m     )\n\u001b[0;32m    650\u001b[0m     \u001b[39mreturn\u001b[39;00m output\n\u001b[0;32m    651\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(missing_prompts) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Yiche\\.conda\\envs\\Butis\\lib\\site-packages\\langchain\\llms\\base.py:535\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[39mfor\u001b[39;00m run_manager \u001b[39min\u001b[39;00m run_managers:\n\u001b[0;32m    534\u001b[0m         run_manager\u001b[39m.\u001b[39mon_llm_error(e)\n\u001b[1;32m--> 535\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    536\u001b[0m flattened_outputs \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mflatten()\n\u001b[0;32m    537\u001b[0m \u001b[39mfor\u001b[39;00m manager, flattened_output \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[1;32mc:\\Users\\Yiche\\.conda\\envs\\Butis\\lib\\site-packages\\langchain\\llms\\base.py:522\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_generate_helper\u001b[39m(\n\u001b[0;32m    513\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    514\u001b[0m     prompts: List[\u001b[39mstr\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    518\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[0;32m    519\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[0;32m    520\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    521\u001b[0m         output \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 522\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(\n\u001b[0;32m    523\u001b[0m                 prompts,\n\u001b[0;32m    524\u001b[0m                 stop\u001b[39m=\u001b[39;49mstop,\n\u001b[0;32m    525\u001b[0m                 \u001b[39m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[0;32m    526\u001b[0m                 run_manager\u001b[39m=\u001b[39;49mrun_managers[\u001b[39m0\u001b[39;49m] \u001b[39mif\u001b[39;49;00m run_managers \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    527\u001b[0m                 \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m    528\u001b[0m             )\n\u001b[0;32m    529\u001b[0m             \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    530\u001b[0m             \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(prompts, stop\u001b[39m=\u001b[39mstop)\n\u001b[0;32m    531\u001b[0m         )\n\u001b[0;32m    532\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    533\u001b[0m         \u001b[39mfor\u001b[39;00m run_manager \u001b[39min\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\Users\\Yiche\\.conda\\envs\\Butis\\lib\\site-packages\\langchain\\llms\\huggingface_pipeline.py:183\u001b[0m, in \u001b[0;36mHuggingFacePipeline._generate\u001b[1;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    180\u001b[0m batch_prompts \u001b[39m=\u001b[39m prompts[i : i \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size]\n\u001b[0;32m    182\u001b[0m \u001b[39m# Process batch of prompts\u001b[39;00m\n\u001b[1;32m--> 183\u001b[0m responses \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpipeline(batch_prompts)\n\u001b[0;32m    185\u001b[0m \u001b[39m# Process each response in the batch\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[39mfor\u001b[39;00m j, response \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(responses):\n",
      "File \u001b[1;32mc:\\Users\\Yiche\\.conda\\envs\\Butis\\lib\\site-packages\\transformers\\pipelines\\text_generation.py:208\u001b[0m, in \u001b[0;36mTextGenerationPipeline.__call__\u001b[1;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, text_inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    168\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \u001b[39m    Complete the prompt(s) given as inputs.\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39m          ids of the generated text.\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(text_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Yiche\\.conda\\envs\\Butis\\lib\\site-packages\\transformers\\pipelines\\base.py:1121\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1117\u001b[0m \u001b[39mif\u001b[39;00m can_use_iterator:\n\u001b[0;32m   1118\u001b[0m     final_iterator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_iterator(\n\u001b[0;32m   1119\u001b[0m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[0;32m   1120\u001b[0m     )\n\u001b[1;32m-> 1121\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(final_iterator)\n\u001b[0;32m   1122\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs\n\u001b[0;32m   1123\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Yiche\\.conda\\envs\\Butis\\lib\\site-packages\\transformers\\pipelines\\pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader_batch_item()\n\u001b[0;32m    123\u001b[0m \u001b[39m# We're out of items within a batch\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m item \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterator)\n\u001b[0;32m    125\u001b[0m processed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfer(item, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams)\n\u001b[0;32m    126\u001b[0m \u001b[39m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Yiche\\.conda\\envs\\Butis\\lib\\site-packages\\transformers\\pipelines\\pt_utils.py:125\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[39m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m    124\u001b[0m item \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterator)\n\u001b[1;32m--> 125\u001b[0m processed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minfer(item, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams)\n\u001b[0;32m    126\u001b[0m \u001b[39m# We now have a batch of \"inferred things\".\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader_batch_size \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    128\u001b[0m     \u001b[39m# Try to infer the size of the batch\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Yiche\\.conda\\envs\\Butis\\lib\\site-packages\\transformers\\pipelines\\base.py:1046\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[1;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[0;32m   1044\u001b[0m     \u001b[39mwith\u001b[39;00m inference_context():\n\u001b[0;32m   1045\u001b[0m         model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m-> 1046\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward(model_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mforward_params)\n\u001b[0;32m   1047\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m   1048\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Yiche\\.conda\\envs\\Butis\\lib\\site-packages\\transformers\\pipelines\\text_generation.py:271\u001b[0m, in \u001b[0;36mTextGenerationPipeline._forward\u001b[1;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[0;32m    268\u001b[0m         generate_kwargs[\u001b[39m\"\u001b[39m\u001b[39mmin_length\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m prefix_length\n\u001b[0;32m    270\u001b[0m \u001b[39m# BS x SL\u001b[39;00m\n\u001b[1;32m--> 271\u001b[0m generated_sequence \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mgenerate(input_ids\u001b[39m=\u001b[39;49minput_ids, attention_mask\u001b[39m=\u001b[39;49mattention_mask, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mgenerate_kwargs)\n\u001b[0;32m    272\u001b[0m out_b \u001b[39m=\u001b[39m generated_sequence\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m    273\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframework \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Yiche\\.conda\\envs\\Butis\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Yiche\\.conda\\envs\\Butis\\lib\\site-packages\\transformers\\generation\\utils.py:1652\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   1644\u001b[0m     input_ids, model_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   1645\u001b[0m         input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[0;32m   1646\u001b[0m         expand_size\u001b[39m=\u001b[39mgeneration_config\u001b[39m.\u001b[39mnum_return_sequences,\n\u001b[0;32m   1647\u001b[0m         is_encoder_decoder\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   1648\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1649\u001b[0m     )\n\u001b[0;32m   1651\u001b[0m     \u001b[39m# 13. run sample\u001b[39;00m\n\u001b[1;32m-> 1652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msample(\n\u001b[0;32m   1653\u001b[0m         input_ids,\n\u001b[0;32m   1654\u001b[0m         logits_processor\u001b[39m=\u001b[39;49mlogits_processor,\n\u001b[0;32m   1655\u001b[0m         logits_warper\u001b[39m=\u001b[39;49mlogits_warper,\n\u001b[0;32m   1656\u001b[0m         stopping_criteria\u001b[39m=\u001b[39;49mstopping_criteria,\n\u001b[0;32m   1657\u001b[0m         pad_token_id\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49mpad_token_id,\n\u001b[0;32m   1658\u001b[0m         eos_token_id\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49meos_token_id,\n\u001b[0;32m   1659\u001b[0m         output_scores\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49moutput_scores,\n\u001b[0;32m   1660\u001b[0m         return_dict_in_generate\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49mreturn_dict_in_generate,\n\u001b[0;32m   1661\u001b[0m         synced_gpus\u001b[39m=\u001b[39;49msynced_gpus,\n\u001b[0;32m   1662\u001b[0m         streamer\u001b[39m=\u001b[39;49mstreamer,\n\u001b[0;32m   1663\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[0;32m   1664\u001b[0m     )\n\u001b[0;32m   1666\u001b[0m \u001b[39melif\u001b[39;00m generation_mode \u001b[39m==\u001b[39m GenerationMode\u001b[39m.\u001b[39mBEAM_SEARCH:\n\u001b[0;32m   1667\u001b[0m     \u001b[39m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[0;32m   1668\u001b[0m     beam_scorer \u001b[39m=\u001b[39m BeamSearchScorer(\n\u001b[0;32m   1669\u001b[0m         batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1670\u001b[0m         num_beams\u001b[39m=\u001b[39mgeneration_config\u001b[39m.\u001b[39mnum_beams,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1675\u001b[0m         max_length\u001b[39m=\u001b[39mgeneration_config\u001b[39m.\u001b[39mmax_length,\n\u001b[0;32m   1676\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Yiche\\.conda\\envs\\Butis\\lib\\site-packages\\transformers\\generation\\utils.py:2770\u001b[0m, in \u001b[0;36mGenerationMixin.sample\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[0;32m   2768\u001b[0m \u001b[39m# sample\u001b[39;00m\n\u001b[0;32m   2769\u001b[0m probs \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39msoftmax(next_token_scores, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m-> 2770\u001b[0m next_tokens \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmultinomial(probs, num_samples\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m)\n\u001b[0;32m   2772\u001b[0m \u001b[39m# finished sentences should have their next token be a padding token\u001b[39;00m\n\u001b[0;32m   2773\u001b[0m \u001b[39mif\u001b[39;00m eos_token_id \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate(template=template4, input_variables=[\"source\", \"summary\"])\n",
    "llm_chain = LLMChain(prompt=prompt, \n",
    "                     llm=llm)\n",
    "result1 = llm_chain.run(source=source, summary=true_summary)\n",
    "pprint.pprint(result1)\n",
    "result1 = llm_chain.run(source=source, summary=false_summary1)\n",
    "pprint.pprint(result1)\n",
    "result1 = llm_chain.run(source=source, summary=false_summary2)\n",
    "pprint.pprint(result1)\n",
    "result1 = llm_chain.run(source=source, summary=false_summary3)\n",
    "pprint.pprint(result1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Butis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
